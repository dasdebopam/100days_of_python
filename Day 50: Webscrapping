'''
Question:
You need to download a file of weather data from a government website. files that are sitting at the following specified location.
https://www.ncei.noaa.gov/data/local-climatological-data/access/2021/
You are looking for the file that was Last Modified on 2022-02-07 14:03, you can't cheat and lookup the file number yourself. You must use Python to scrape this webpage, finding the corresponding file-name for this timestamp, 2022-02-07 14:03
Once you have obtained the correct file, and downloaded it, you must load the file into Pandas and find the record(s) with the highest HourlyDryBulbTemperature. Print these record(s) to the command line.
Generally, your script should do the following ...
Attempt to web scrap/pull down the contents of https://www.ncei.noaa.gov/data/local-climatological-data/access/2021/
Analyze it's structure, determine how to find the corresponding file to 2022-02-07 14:03 using Python.
Build the URL required to download this file, and write the file locally.
Open the file with Pandas and find the records with the highest HourlyDryBulbTemperature.
Print this to stdout/command line/terminal.

Input:
Original:https://www.ncei.noaa.gov/data/local-climatological-data/access/2021/
One in Use:https://forecast.weather.gov/MapClick.php?lat=41.884250000000065&lon=-87.63244999999995#.XtpdeOfhXIX

Output:
,Period,Short Description,Temperature
0,Today,Breezy.Showers thenShowersLikely,High: 55 °F
1,Tonight,ShowersLikely andBreezy,Low: 49 °F
2,Sunday,ShowersLikely,High: 54 °F
3,SundayNight,ChanceShowers,Low: 49 °F
4,Monday,Slight ChanceShowers,High: 55 °F
5,MondayNight,Mostly Cloudy,Low: 46 °F
6,Tuesday,Mostly Sunny,High: 58 °F
7,TuesdayNight,Partly Cloudy,Low: 46 °F
8,Wednesday,Partly Sunny,High: 64 °F
'''
import pandas as pd
import requests
from bs4 import BeautifulSoup

url = "https://forecast.weather.gov/MapClick.php?lat=41.884250000000065&lon=-87.63244999999995#.XtpdeOfhXIX"


def main(l):
    r = requests.get(l)
    if r.status_code == 200:
        soup = BeautifulSoup(r.content, "html.parser")
        items = soup.find_all("div", class_="tombstone-container")
        period_name = [item.find(class_="period-name").get_text() for item in items]
        short_desc = [item.find(class_="short-desc").get_text() for item in items]
        temp = [item.find(class_="temp").get_text() for item in items]
        df = pd.DataFrame({"Period": period_name, "Short Description": short_desc, "Temperature": temp})
        df.to_csv("WeatherData.csv")


if __name__ == '__main__':
    main(url)

'''
Thought:
was unable to access the site given by DinealBeach so found a new one instead
had to use BeautifulSoup and take help from: https://shailchudgar005.medium.com/web-scraping-using-python-weather-data-71a8194d9c01
'''
